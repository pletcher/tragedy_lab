{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (5.3.0)\n",
      "Requirement already satisfied: polars in ./.venv/lib/python3.12/site-packages (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/pletcher/code/writing/articles/2024-11-28_tragedy-dfs/.venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (44_378, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>n</th><th>urn</th><th>dramatist</th><th>title</th><th>title_en</th><th>speaker</th><th>text</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1&quot;</td><td>&quot;urn:cts:greekLit:tlg0006.tlg01…</td><td>&quot;Euripides&quot;</td><td>&quot;Ἰφιγένεια ἐν Ταύροις&quot;</td><td>&quot;Ifigeneia en Taurois&quot;</td><td>&quot;Ἰφιγένεια&quot;</td><td>&quot;Πέλοψ ὁ Ταντάλειος ἐς Πῖσαν μο…</td></tr><tr><td>&quot;2&quot;</td><td>&quot;urn:cts:greekLit:tlg0006.tlg01…</td><td>&quot;Euripides&quot;</td><td>&quot;Ἰφιγένεια ἐν Ταύροις&quot;</td><td>&quot;Ifigeneia en Taurois&quot;</td><td>&quot;Ἰφιγένεια&quot;</td><td>&quot;θοαῖσιν ἵπποις Οἰνομάου γαμεῖ …</td></tr><tr><td>&quot;3&quot;</td><td>&quot;urn:cts:greekLit:tlg0006.tlg01…</td><td>&quot;Euripides&quot;</td><td>&quot;Ἰφιγένεια ἐν Ταύροις&quot;</td><td>&quot;Ifigeneia en Taurois&quot;</td><td>&quot;Ἰφιγένεια&quot;</td><td>&quot;ἐξ ἧς Ἀτρεὺς ἔβλαστεν· Ἀτρέως …</td></tr><tr><td>&quot;4&quot;</td><td>&quot;urn:cts:greekLit:tlg0006.tlg01…</td><td>&quot;Euripides&quot;</td><td>&quot;Ἰφιγένεια ἐν Ταύροις&quot;</td><td>&quot;Ifigeneia en Taurois&quot;</td><td>&quot;Ἰφιγένεια&quot;</td><td>&quot;Μενέλαος Ἀγαμέμνων τε· τοῦ δʼ …</td></tr><tr><td>&quot;5&quot;</td><td>&quot;urn:cts:greekLit:tlg0006.tlg01…</td><td>&quot;Euripides&quot;</td><td>&quot;Ἰφιγένεια ἐν Ταύροις&quot;</td><td>&quot;Ifigeneia en Taurois&quot;</td><td>&quot;Ἰφιγένεια&quot;</td><td>&quot;τῆς Τυνδαρείας θυγατρὸς Ἰφιγέν…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;1526&quot;</td><td>&quot;urn:cts:greekLit:tlg0011.tlg00…</td><td>&quot;Sophocles&quot;</td><td>&quot;Οἰδίπους Τύραννος&quot;</td><td>&quot;Oidipoys Turannos&quot;</td><td>&quot;Χορός&quot;</td><td>&quot;οὗ τίς οὐ ζήλῳ πολιτῶν ἦν τύχα…</td></tr><tr><td>&quot;1527&quot;</td><td>&quot;urn:cts:greekLit:tlg0011.tlg00…</td><td>&quot;Sophocles&quot;</td><td>&quot;Οἰδίπους Τύραννος&quot;</td><td>&quot;Oidipoys Turannos&quot;</td><td>&quot;Χορός&quot;</td><td>&quot;εἰς ὅσον κλύδωνα δεινῆς συμφορ…</td></tr><tr><td>&quot;1528&quot;</td><td>&quot;urn:cts:greekLit:tlg0011.tlg00…</td><td>&quot;Sophocles&quot;</td><td>&quot;Οἰδίπους Τύραννος&quot;</td><td>&quot;Oidipoys Turannos&quot;</td><td>&quot;Χορός&quot;</td><td>&quot;ὥστε θνητὸν ὄντα κείνην τὴν τε…</td></tr><tr><td>&quot;1529&quot;</td><td>&quot;urn:cts:greekLit:tlg0011.tlg00…</td><td>&quot;Sophocles&quot;</td><td>&quot;Οἰδίπους Τύραννος&quot;</td><td>&quot;Oidipoys Turannos&quot;</td><td>&quot;Χορός&quot;</td><td>&quot;ἡμέραν ἐπισκοποῦντα μηδένʼ ὀλβ…</td></tr><tr><td>&quot;1530&quot;</td><td>&quot;urn:cts:greekLit:tlg0011.tlg00…</td><td>&quot;Sophocles&quot;</td><td>&quot;Οἰδίπους Τύραννος&quot;</td><td>&quot;Oidipoys Turannos&quot;</td><td>&quot;Χορός&quot;</td><td>&quot;τέρμα τοῦ βίου περάσῃ&nbsp;&nbsp;μηδὲν ἀ…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (44_378, 7)\n",
       "┌──────┬────────────────┬───────────┬────────────────┬────────────────┬───────────┬────────────────┐\n",
       "│ n    ┆ urn            ┆ dramatist ┆ title          ┆ title_en       ┆ speaker   ┆ text           │\n",
       "│ ---  ┆ ---            ┆ ---       ┆ ---            ┆ ---            ┆ ---       ┆ ---            │\n",
       "│ str  ┆ str            ┆ str       ┆ str            ┆ str            ┆ str       ┆ str            │\n",
       "╞══════╪════════════════╪═══════════╪════════════════╪════════════════╪═══════════╪════════════════╡\n",
       "│ 1    ┆ urn:cts:greekL ┆ Euripides ┆ Ἰφιγένεια ἐν   ┆ Ifigeneia en   ┆ Ἰφιγένεια ┆ Πέλοψ ὁ        │\n",
       "│      ┆ it:tlg0006.tlg ┆           ┆ Ταύροις        ┆ Taurois        ┆           ┆ Ταντάλειος ἐς  │\n",
       "│      ┆ 01…            ┆           ┆                ┆                ┆           ┆ Πῖσαν μο…      │\n",
       "│ 2    ┆ urn:cts:greekL ┆ Euripides ┆ Ἰφιγένεια ἐν   ┆ Ifigeneia en   ┆ Ἰφιγένεια ┆ θοαῖσιν ἵπποις │\n",
       "│      ┆ it:tlg0006.tlg ┆           ┆ Ταύροις        ┆ Taurois        ┆           ┆ Οἰνομάου γαμεῖ │\n",
       "│      ┆ 01…            ┆           ┆                ┆                ┆           ┆ …              │\n",
       "│ 3    ┆ urn:cts:greekL ┆ Euripides ┆ Ἰφιγένεια ἐν   ┆ Ifigeneia en   ┆ Ἰφιγένεια ┆ ἐξ ἧς Ἀτρεὺς   │\n",
       "│      ┆ it:tlg0006.tlg ┆           ┆ Ταύροις        ┆ Taurois        ┆           ┆ ἔβλαστεν·      │\n",
       "│      ┆ 01…            ┆           ┆                ┆                ┆           ┆ Ἀτρέως …       │\n",
       "│ 4    ┆ urn:cts:greekL ┆ Euripides ┆ Ἰφιγένεια ἐν   ┆ Ifigeneia en   ┆ Ἰφιγένεια ┆ Μενέλαος       │\n",
       "│      ┆ it:tlg0006.tlg ┆           ┆ Ταύροις        ┆ Taurois        ┆           ┆ Ἀγαμέμνων τε·  │\n",
       "│      ┆ 01…            ┆           ┆                ┆                ┆           ┆ τοῦ δʼ …       │\n",
       "│ 5    ┆ urn:cts:greekL ┆ Euripides ┆ Ἰφιγένεια ἐν   ┆ Ifigeneia en   ┆ Ἰφιγένεια ┆ τῆς Τυνδαρείας │\n",
       "│      ┆ it:tlg0006.tlg ┆           ┆ Ταύροις        ┆ Taurois        ┆           ┆ θυγατρὸς       │\n",
       "│      ┆ 01…            ┆           ┆                ┆                ┆           ┆ Ἰφιγέν…        │\n",
       "│ …    ┆ …              ┆ …         ┆ …              ┆ …              ┆ …         ┆ …              │\n",
       "│ 1526 ┆ urn:cts:greekL ┆ Sophocles ┆ Οἰδίπους       ┆ Oidipoys       ┆ Χορός     ┆ οὗ τίς οὐ ζήλῳ │\n",
       "│      ┆ it:tlg0011.tlg ┆           ┆ Τύραννος       ┆ Turannos       ┆           ┆ πολιτῶν ἦν     │\n",
       "│      ┆ 00…            ┆           ┆                ┆                ┆           ┆ τύχα…          │\n",
       "│ 1527 ┆ urn:cts:greekL ┆ Sophocles ┆ Οἰδίπους       ┆ Oidipoys       ┆ Χορός     ┆ εἰς ὅσον       │\n",
       "│      ┆ it:tlg0011.tlg ┆           ┆ Τύραννος       ┆ Turannos       ┆           ┆ κλύδωνα δεινῆς │\n",
       "│      ┆ 00…            ┆           ┆                ┆                ┆           ┆ συμφορ…        │\n",
       "│ 1528 ┆ urn:cts:greekL ┆ Sophocles ┆ Οἰδίπους       ┆ Oidipoys       ┆ Χορός     ┆ ὥστε θνητὸν    │\n",
       "│      ┆ it:tlg0011.tlg ┆           ┆ Τύραννος       ┆ Turannos       ┆           ┆ ὄντα κείνην    │\n",
       "│      ┆ 00…            ┆           ┆                ┆                ┆           ┆ τὴν τε…        │\n",
       "│ 1529 ┆ urn:cts:greekL ┆ Sophocles ┆ Οἰδίπους       ┆ Oidipoys       ┆ Χορός     ┆ ἡμέραν         │\n",
       "│      ┆ it:tlg0011.tlg ┆           ┆ Τύραννος       ┆ Turannos       ┆           ┆ ἐπισκοποῦντα   │\n",
       "│      ┆ 00…            ┆           ┆                ┆                ┆           ┆ μηδένʼ ὀλβ…    │\n",
       "│ 1530 ┆ urn:cts:greekL ┆ Sophocles ┆ Οἰδίπους       ┆ Oidipoys       ┆ Χορός     ┆ τέρμα τοῦ βίου │\n",
       "│      ┆ it:tlg0011.tlg ┆           ┆ Τύραννος       ┆ Turannos       ┆           ┆ περάσῃ  μηδὲν  │\n",
       "│      ┆ 00…            ┆           ┆                ┆                ┆           ┆ ἀ…             │\n",
       "└──────┴────────────────┴───────────┴────────────────┴────────────────┴───────────┴────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_parquet(\"./greek-tragedy-by-line.parquet\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "### stylo version: 0.7.5 ###\n",
      "\n",
      "If you plan to cite this software (please do!), use the following reference:\n",
      "    Eder, M., Rybicki, J. and Kestemont, M. (2016). Stylometry with R:\n",
      "    a package for computational text analysis. R Journal 8(1): 107-121.\n",
      "    <https://journal.r-project.org/archive/2016/RJ-2016-007/index.html>\n",
      "\n",
      "To get full BibTeX entry, type: citation(\"stylo\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 9 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'stylo'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'tools'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'stats'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'datasets'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'methods'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'base'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x119098f50> [16]\n",
       "R classes: ('character',)\n",
       "['stylo', 'tools', 'stats', 'graphics', ..., 'utils', 'datasets', 'methods', 'base']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "\n",
    "R = ro.r\n",
    "\n",
    "R.library(\"stylo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: using current directory...\n",
      "\n",
      "R[write to console]: Performing no sampling (using entire text as sample)\n",
      "\n",
      "\n",
      "R[write to console]: slicing input text into tokens...\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "turning words into features, e.g. char n-grams (if applicable)...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Total nr. of samples in the corpus: 34\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: The corpus consists of 3 tokens\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: processing  34  text samples\n",
      "\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: combining frequencies into a table...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "\n",
      "R[write to console]: culling @ 0\tavailable features (words) 3\n",
      "\n",
      "R[write to console]: Calculating z-scores... \n",
      "\n",
      "\n",
      "R[write to console]: Calculating classic Delta distances...\n",
      "\n",
      "R[write to console]: MFW used: \n",
      "\n",
      "R[write to console]: 3 \n",
      "R[write to console]:  \n",
      "\n",
      "R[write to console]: using current directory...\n",
      "\n",
      "R[write to console]: Performing no sampling (using entire text as sample)\n",
      "\n",
      "\n",
      "R[write to console]: slicing input text into tokens...\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "turning words into features, e.g. char n-grams (if applicable)...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Total nr. of samples in the corpus: 34\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: The corpus consists of 3 tokens\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: processing  34  text samples\n",
      "\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: combining frequencies into a table...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "\n",
      "R[write to console]: culling @ 0\tavailable features (words) 3\n",
      "\n",
      "R[write to console]: Calculating z-scores... \n",
      "\n",
      "\n",
      "R[write to console]: Calculating classic Delta distances...\n",
      "\n",
      "R[write to console]: MFW used: \n",
      "\n",
      "R[write to console]: 3 \n",
      "R[write to console]:  \n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Function call:\n",
      "\n",
      "R[write to console]: (function (gui = TRUE, frequencies = NULL, parsed.corpus = NULL,     features = NULL, path = NULL, metadata = NULL, filename.column = \"filename\",     grouping.column = \"author\", corpus.dir = \"corpus\", ...) {    passed.arguments = list(...)    original.path = getwd()    if (is.character(path) == TRUE & length(path) > 0) {        if (file.exists(path) == TRUE & file.info(path)[2] ==             TRUE) {            setwd(path)        }        else {            stop(\"there is no directory \", getwd(), \"/\", path)        }    }    else {        message(\"using current directory...\")    }    if (is.character(corpus.dir) == FALSE | nchar(corpus.dir) ==         0) {        corpus.dir = \"corpus\"    }    variables = stylo.default.settings(...)    if (gui == TRUE) {        if (.Platform$OS.type == \"windows\" || .Platform$GUI ==             \"AQUA\" || (capabilities(\"tcltk\") && capabilities(\"X11\") &&             suppressWarnings(tcltk::.TkUp))) {            variables = gui.stylo(...)        }        else {            message(\" \")            message(\"GUI could not be launched -- default settings will be used;\")            message(\"otherwise please pass your variables as command-line agruments\\n\")        }    }    add.to.margins = variables$add.to.margins    analysis.type = variables$analysis.type    analyzed.features = variables$analyzed.features    classification.method = variables$classification.method    colors.on.graphs = variables$colors.on.graphs    consensus.strength = variables$consensus.strength    corpus.format = variables$corpus.format    corpus.lang = variables$corpus.lang    culling.incr = variables$culling.incr    culling.max = variables$culling.max    culling.min = variables$culling.min    culling.of.all.samples = variables$culling.of.all.samples    custom.graph.title = variables$custom.graph.title    delete.pronouns = variables$delete.pronouns    dendrogram.layout.horizontal = variables$dendrogram.layout.horizontal    display.on.screen = variables$display.on.screen    distance.measure = variables$distance.measure    dump.samples = variables$dump.samples    final.ranking.of.candidates = variables$final.ranking.of.candidates    how.many.correct.attributions = variables$how.many.correct.attributions    interactive.files = variables$interactive.files    k.value = variables$k.value    l.value = variables$l.value    label.offset = variables$label.offset    mfw.incr = variables$mfw.incr    mfw.list.cutoff = variables$mfw.list.cutoff    mfw.max = variables$mfw.max    mfw.min = variables$mfw.min    ngram.size = variables$ngram.size    preserve.case = variables$preserve.case    number.of.candidates = variables$number.of.candidates    outputfile = variables$outputfile    passed.arguments = variables$passed.arguments    pca.visual.flavour = variables$pca.visual.flavour    plot.custom.height = variables$plot.custom.height    plot.custom.width = variables$plot.custom.width    plot.font.size = variables$plot.font.size    plot.line.thickness = variables$plot.line.thickness    plot.options.reset = variables$plot.options.reset    reference.wordlist.of.all.samples = variables$reference.wordlist.of.all.samples    sample.size = variables$sample.size    sampling = variables$sampling    sampling.with.replacement = variables$sampling.with.replacement    save.analyzed.features = variables$save.analyzed.features    save.analyzed.freqs = variables$save.analyzed.freqs    save.distance.tables = variables$save.distance.tables    start.at = variables$start.at    svm.coef0 = variables$svm.coef0    svm.cost = variables$svm.cost    svm.degree = variables$svm.degree    svm.kernel = variables$svm.kernel    text.id.on.graphs = variables$text.id.on.graphs    titles.on.graphs = variables$titles.on.graphs    txm.compatibility.mode = variables$txm.compatibility.mode    use.custom.list.of.files = variables$use.custom.list.of.files    use.existing.freq.tables = variables$use.existing.freq.tables    use.existing.wordlist = variables$use.existing.wordlist    write.jpg.file = variables$write.jpg.file    write.pdf.file = variables$write.pdf.file    write.png.file = variables$write.png.file    write.svg.file = variables$write.svg.file    z.scores.of.all.samples = variables$z.scores.of.all.samples    linkage = variables$linkage    network = variables$network    network.tables = variables$network.tables    network.type = variables$network.type    linked.neighbors = variables$linked.neighbors    edge.weights = variables$edge.weights    relative.frequencies = variables$relative.frequencies    splitting.rule = variables$splitting.rule    preserve.case = variables$preserve.case    encoding = variables$encoding    stop.words = variables$stop.words    sample.overlap = variables$sample.overlap    number.of.samples = variables$number.of.samples    custom.graph.filename = variables$custom.graph.filename    pronouns = stylo.pronouns(corpus.lang = corpus.lang)    mfw.min = round(mfw.min)    mfw.max = round(mfw.max)    mfw.incr = round(mfw.incr)    start.at = round(start.at)    culling.min = round(culling.min)    culling.max = round(culling.max)    culling.incr = round(culling.incr)    mfw.list.cutoff = round(mfw.list.cutoff)    sample.size = round(sample.size)    if (plot.options.reset == TRUE) {        plot.custom.height = 7        plot.custom.width = 7        plot.font.size = 10        plot.line.thickness = 1        plot.options.reset = FALSE    }    if (txm.compatibility.mode == TRUE) {        if (exists(\"txm.generated.freq.table\") == TRUE) {            if (exists(\"variable.name\") == FALSE) {                variable.name = c()                stop(\"TXM does not seem to pass any data to analyze\")            }            frequencies.0.culling = t(variable.name)            frequencies.0.culling = frequencies.0.culling[-1,                 ]            use.existing.freq.tables == TRUE        }        else {            message(\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                 \"Oops! To use TXM compatibility mode, you have to launch TXM first!\\n\",                 \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")            stop(\"Incorrect input data\")        }    }    if (use.existing.freq.tables == TRUE & file.exists(\"table_with_frequencies.txt\") ==         TRUE) {        frequencies = \"table_with_frequencies.txt\"    }    else {        use.existing.freq.tables = FALSE    }    if (use.existing.wordlist == TRUE & file.exists(\"wordlist.txt\") ==         TRUE) {        features = \"wordlist.txt\"    }    else {        use.existing.wordlist = FALSE    }    all.connections = 0    if (is.null(custom.graph.title) == FALSE) {        graph.title = as.character(custom.graph.title)[1]        graph.main.title = graph.title    }    else {        graph.title = basename(getwd())        graph.main.title = graph.title    }    if (text.id.on.graphs != \"both\") {        label.offset = 0    }    if (write.jpg.file == TRUE || write.png.file == TRUE) {        if (300 * plot.custom.width * 300 * plot.custom.height >             3.6e+07) {            cat(\"\\nYou have chosen a bitmap output format and quite a large plot area\\n\")            cat(\"of\", plot.custom.width, \"by\", plot.custom.height,                 \"inches. Producing some\", as.integer(300 * plot.custom.width *                   300 * plot.custom.height/1e+06), \"Megapixels will take a good while.\\n\\n\")            cat(\"  i - ignore this warning and continue with the current settings\\n\")            cat(\"  p - use pdf format instead of a bitmap (default)\\n\")            cat(\"  s - shrink the plot area to a reasonable size of 20x20 inches\\n\")            cat(\"  a - abort the script\\n\")            answer = readline(\"\\n[i/p/s/a]  \")            if (tolower(answer) == \"a\") {                stop(\"The script stopped by the user\")            }            else if (tolower(answer) == \"i\") {                cat(\"Okay (but honestly, do you really need such a large plot?)\\n\")            }            else if (tolower(answer) == \"s\") {                cat(\"The plot area will be shrunken to 20x20 inches\\n\")                plot.custom.width = 20                plot.custom.height = 20            }            else {                cat(\"Withdrawing from the bitmap output, performing pdf instead\\n\")                write.jpg.file = FALSE                write.svg.file = FALSE                write.png.file = FALSE                write.pdf.file = TRUE            }        }    }    features.exist = FALSE    if (length(features) > 1) {        if (is.vector(features) == TRUE) {            features = as.character(features)            mfw.list.of.all = features        }        else {            message(\"\")            message(\"You seem to have chosen an existing set of features\")            message(\"Unfortunately, something is wrong: check if your variable\")            message(\"has a form of vector\")            stop(\"Wrong format: a vector of features (e.g. words) was expected\")        }        features.exist = TRUE    }    if (length(features) == 1) {        features = as.character(features)        if (file.exists(features) == TRUE) {            message(\"\\nreading a custom set of features from a file...\")            features = scan(features, what = \"char\", sep = \"\\n\",                 encoding = encoding)            features = c(grep(\"^[^#]\", features, value = TRUE))            mfw.list.of.all = features        }        else {            message(\"\\n\", \"file \\\"\", features, \"\\\" could not be found\")            stop(\"Wrong file name\")        }        features.exist = TRUE    }    corpus.exists = FALSE    if (length(frequencies) > 1) {        if (is.matrix(frequencies) == TRUE | is.data.frame(frequencies) ==             TRUE) {            frequencies = as.matrix(frequencies)        }        else {            message(\"\")            message(\"You seem to have chosen an existing table with frequencies\")            message(\"Unfortunately, something is wrong: check if your variable\")            message(\"has a form of matrix/data frame\")            stop(\"Wrong format of the table of frequencies\")        }        if (length(colnames(frequencies)) == 0) {            colnames(frequencies) = paste(\"var\", 1:length(frequencies[1,                 ]), sep = \"_\")        }        if (length(rownames(frequencies)) == 0) {            rownames(frequencies) = paste(\"sample\", 1:length(frequencies[,                 1]), sep = \"_\")        }        corpus.exists = TRUE    }    if (length(frequencies) == 1) {        frequencies = as.character(frequencies)        if (file.exists(frequencies) == TRUE) {            message(\"\\n\", \"reading a file containing frequencies...\")            frequencies = t(read.table(frequencies, encoding = encoding))        }        else {            message(\"\\n\", \"file \\\"\", frequencies, \"\\\" could not be found\")            stop(\"Wrong file name\")        }        corpus.exists = TRUE    }    if (features.exist == TRUE & corpus.exists == TRUE) {        if (length(grep(\"TRUE\", colnames(frequencies) %in% features)) <             2) {            message(\"The features you want to analyze do not match the variables' names:\\n\")            message(\"Available features: \", head(colnames(frequencies)),                 \"...\")            message(\"Chosen features: \", head(features), \"...\")            message(\"\")            message(\"Check the rotation of your table and the names of its rows and columns.\")            stop(\"Input data mismatch\")        }        else {            frequencies = frequencies[, colnames(frequencies) %in%                 features]        }    }    if (features.exist == FALSE & corpus.exists == TRUE) {        features = colnames(frequencies)        mfw.list.of.all = features    }    if (corpus.exists == TRUE) {        if (length(frequencies[, 1]) < 2 | length(frequencies[1,             ]) < 2) {            message(\"\\n\")            message(\"There is not enough samples and/or features to be analyzed.\\n\")            message(\"Try to use tables of at least two rows by two columns.\\n\")            message(\"\\n\")            stop(\"Wrong size of the table of frequencies\")        }    }    if (corpus.exists == TRUE) {        frequencies.0.culling = frequencies    }    if (corpus.exists == FALSE & length(parsed.corpus) > 0) {        if (is.list(parsed.corpus) == TRUE & length(parsed.corpus) >             1) {            if (length(names(parsed.corpus)) != length(parsed.corpus)) {                names(parsed.corpus) = paste(\"sample\", 1:length(parsed.corpus),                   sep = \"_\")            }            loaded.corpus = parsed.corpus            message(\"Corpus loaded successfully.\\n\")            corpus.exists = TRUE        }        else {            message(\"\\n\")            message(\"The object you've specified as your corpus cannot be used.\\n\")            message(\"It should be a list containing particular text samples\\n\")            message(\"(vectors containing sequencies of words/n-grams or other features).\\n\")            message(\"The samples (elements of the list) should have their names.\\n\")            message(\"Alternatively, try to build your corpus from text files (default).\\n\")            message(\"\\n\")            stop(\"Wrong corpus format\")        }    }    if (corpus.exists == FALSE) {        if (file.exists(corpus.dir) == FALSE) {            selected.path = tk_choose.dir(caption = \"Select your working directory. It should have a subdirectory called *corpus* \")            setwd(selected.path)        }        if (file.exists(corpus.dir) == FALSE) {            message(\"\\n\\n\", \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                 \"Hey! The working directory should contain the subdirectory \\\"\",                 corpus.dir, \"\\\"\\n\", \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\n\")            setwd(original.path)            stop(\"Corpus prepared incorrectly\")        }        if (interactive.files == TRUE) {            setwd(corpus.dir)            corpus.filenames = basename(tk_choose.files(default = \"\",                 caption = \"Select at least 2 files\", multi = TRUE))            setwd(\"..\")        }        else {            if (use.custom.list.of.files == TRUE & file.exists(\"files_to_analyze.txt\") ==                 TRUE) {                message(\"\\n\")                message(\"external list of files will be used for uploading the corpus\\n\\n\")                corpus.filenames = scan(\"files_to_analyze.txt\",                   what = \"char\", sep = \"\\n\", encoding = encoding,                   quiet = T)                corpus.filenames = unlist(strsplit(corpus.filenames,                   \"[ \\t]+\"))                if (length(setdiff(corpus.filenames, list.files(corpus.dir))) >                   0) {                  message(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")                  message(\"the following files have not been found:\\n\")                  message(setdiff(corpus.filenames, list.files(corpus.dir)),                     \"\\n\\n\")                  message(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")                  corpus.filenames = intersect(corpus.filenames,                     list.files(corpus.dir))                }            }            else {                corpus.filenames = list.files(corpus.dir)            }        }        if (length(corpus.filenames) < 2 & sampling != \"normal.sampling\") {            message(\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\",                 \"Ho! The subdirectory \\\"\", corpus.dir, \"\\\" should contain at least\\n          two text samples!\\n\",                 \"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\\n\")            setwd(original.path)            stop(\"Corpus prepared incorrectly\")        }        if (sampling == \"normal.sampling\") {            message(\"Performing sampling (using sample size = \",                 sample.size, \" words)\\n\")        }        else if (sampling == \"random.sampling\") {            message(\"Performing random sampling (using random sample size = \",                 \" words)\\n\")        }        else if (sampling == \"no.sampling\") {            message(\"Performing no sampling (using entire text as sample)\",                 \"\\n\")        }        else {            stop(\"Exception raised: something is wrong with the sampling parameter you have\\n            specified...\")        }        loaded.corpus = load.corpus.and.parse(files = corpus.filenames,             corpus.dir = corpus.dir, encoding = encoding, markup.type = corpus.format,             corpus.lang = corpus.lang, splitting.rule = splitting.rule,             sample.size = sample.size, sampling = sampling, sampling.with.replacement = sampling.with.replacement,             sample.overlap = sample.overlap, number.of.samples = number.of.samples,             features = analyzed.features, ngram.size = ngram.size,             preserve.case = preserve.case)    }    if (exists(\"frequencies.0.culling\") == FALSE) {        message(\"\")        message(\"Total nr. of samples in the corpus: \", length(loaded.corpus))        if ((length(loaded.corpus) < 2) & (sampling == \"no.sampling\")) {            message(\"\\n\\n\", \"your corpus folder seems to be empty!\",                 \"\\n\\n\")            stop(\"corpus error\")        }        if (features.exist == TRUE) {            message(\"\")            message(\"using an existing wordlist (vector of features)...\")            mfw.list.of.all = features        }        else {            wordlist.of.loaded.corpus = unlist(loaded.corpus,                 use.names = FALSE)            message(\"\")            message(\"The corpus consists of \", length(c(wordlist.of.loaded.corpus)),                 \" tokens\")            mfw.list.of.all = sort(table(c(wordlist.of.loaded.corpus)),                 decreasing = T)            rm(wordlist.of.loaded.corpus)            if (length(mfw.list.of.all) > mfw.list.cutoff) {                mfw.list.of.all = mfw.list.of.all[1:mfw.list.cutoff]            }            mfw.list.of.all = names(mfw.list.of.all)            cat(\"# This file contains the words that were used for building the table\",                 \"# of frequencies. It can be also used for further tasks, and for this\",                 \"# purpose it can be manually revised, edited, deleted, culled, etc.\",                 \"# You can either delete unwanted words, or mark them with \\\"#\\\"\",                 \"# -----------------------------------------------------------------------\",                 \"\", file = \"wordlist.txt\", sep = \"\\n\")            if (encoding == \"native.enc\") {                data.to.be.saved = mfw.list.of.all            }            else {                data.to.be.saved = iconv(mfw.list.of.all, to = encoding)            }            cat(data.to.be.saved, file = \"wordlist.txt\", sep = \"\\n\",                 append = TRUE)        }        message(\"\")        if (dump.samples == TRUE) {            if (file.exists(\"sample_dump\")) {                unlink(\"sample_dump\", recursive = TRUE)            }            dir.create(\"sample_dump\")            setwd(\"sample_dump\")            for (i in names(loaded.corpus)) {                cat(loaded.corpus[[i]], file = paste(names(loaded.corpus[i]),                   \".txt\", sep = \"\"))            }            setwd(\"..\")        }        frequencies.0.culling = make.table.of.frequencies(corpus = loaded.corpus,             features = mfw.list.of.all, relative = relative.frequencies)        if (encoding == \"native.enc\") {            data.to.be.saved = t(frequencies.0.culling)        }        else {            data.to.be.saved = t(frequencies.0.culling)            rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                 to = encoding)            colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                 to = encoding)        }        write.table(data.to.be.saved, file = \"table_with_frequencies.txt\")    }    cat(\"\", file = \"stylo_config.txt\", append = FALSE)    var.name <- function(x) {        if (is.character(x) == TRUE) {            cat(paste(deparse(substitute(x)), \" = \\\"\", x, \"\\\"\",                 sep = \"\"), file = \"stylo_config.txt\", sep = \"\\n\",                 append = TRUE)        }        else {            cat(paste(deparse(substitute(x)), x, sep = \" = \"),                 file = \"stylo_config.txt\", sep = \"\\n\", append = TRUE)        }    }    var.name(corpus.format)    var.name(corpus.lang)    var.name(analyzed.features)    var.name(ngram.size)    var.name(preserve.case)    var.name(encoding)    var.name(mfw.min)    var.name(mfw.max)    var.name(mfw.incr)    var.name(start.at)    var.name(culling.min)    var.name(culling.max)    var.name(culling.incr)    var.name(mfw.list.cutoff)    var.name(delete.pronouns)    var.name(use.existing.freq.tables)    var.name(use.existing.wordlist)    var.name(use.custom.list.of.files)    var.name(analysis.type)    var.name(consensus.strength)    var.name(distance.measure)    var.name(sampling)    var.name(sample.size)    var.name(number.of.samples)    var.name(display.on.screen)    var.name(write.pdf.file)    var.name(write.jpg.file)    var.name(write.svg.file)    var.name(write.png.file)    var.name(plot.custom.height)    var.name(plot.custom.width)    var.name(plot.font.size)    var.name(plot.line.thickness)    var.name(text.id.on.graphs)    var.name(colors.on.graphs)    var.name(titles.on.graphs)    var.name(label.offset)    var.name(add.to.margins)    var.name(dendrogram.layout.horizontal)    var.name(pca.visual.flavour)    var.name(save.distance.tables)    var.name(save.analyzed.features)    var.name(save.analyzed.freqs)    var.name(dump.samples)    mfw.max.original = mfw.max    number.of.current.iteration = 0    if (analysis.type == \"BCT\") {        bootstrap.list = list()    }    if (culling.max >= 100) {        culling.max = 100    }    if (culling.min >= 100) {        culling.min = 100    }    if (culling.min <= 0) {        culling.min = 0    }    if (culling.max < culling.min) {        culling.max = culling.min    }    if (culling.incr <= 1) {        culling.incr = 10    }    for (j in (culling.min/culling.incr):(culling.max/culling.incr)) {        current.culling = j * culling.incr        table.with.all.freqs = perform.culling(frequencies.0.culling,             current.culling)        if (delete.pronouns == TRUE) {            table.with.all.freqs = delete.stop.words(table.with.all.freqs,                 pronouns)        }        if (is.vector(stop.words) == TRUE) {            table.with.all.freqs = delete.stop.words(table.with.all.freqs,                 stop.words)        }        table.with.all.freqs = table.with.all.freqs[, start.at:length(table.with.all.freqs[1,             ])]        if (mfw.max > length(table.with.all.freqs[1, ])) {            mfw.max = length(table.with.all.freqs[1, ])        }        if (mfw.min < 2) {            mfw.min = 2        }        if (mfw.max < mfw.min) {            mfw.max = mfw.min        }        if ((mfw.max != mfw.min) && (mfw.incr == 0)) {            mfw.incr = 10        }        message(\"\\n\")        message(\"culling @ \", current.culling, \"\\t\", \"available features (words) \",             length(table.with.all.freqs[1, ]))        if ((analysis.type == \"CA\") || (analysis.type == \"BCT\") ||             (analysis.type == \"MDS\")) {            message(\"Calculating z-scores... \\n\")            table.with.all.zscores = scale(table.with.all.freqs)            table.with.all.zscores = table.with.all.zscores[,                 ]        }        if ((analysis.type == \"CA\") || (analysis.type == \"BCT\") ||             (analysis.type == \"MDS\")) {            distance.name.on.graph = distance.measure            distance.name.on.file = distance.measure            if (distance.measure == \"delta\" | distance.measure ==                 \"dist.delta\") {                message(\"Calculating classic Delta distances...\")                distance.name.on.graph = \"Classic Delta distance\"                distance.name.on.file = \"Classic Delta\"            }            else if (distance.measure == \"argamon\" | distance.measure ==                 \"dist.argamon\") {                message(\"Calculating Argamon's Delta distances...\")                distance.name.on.graph = \"Argamon's Delta distance\"                distance.name.on.file = \"Argamon's Delta\"            }            else if (distance.measure == \"eder\" | distance.measure ==                 \"dist.eder\") {                message(\"Calculating Eder's Delta distances...\")                distance.name.on.graph = \"Eder's Delta distance\"                distance.name.on.file = \"Eder's Delta\"            }            else if (distance.measure == \"simple\" | distance.measure ==                 \"dist.simple\") {                message(\"Calculating Eder's Simple distances...\")                distance.name.on.graph = \"Eder's Simple distance\"                distance.name.on.file = \"Eder's Simple\"            }            else if (distance.measure == \"manhattan\" | distance.measure ==                 \"dist.manhattan\") {                message(\"Calculating Manhattan distances...\")                distance.name.on.graph = \"Manhattan distance\"                distance.name.on.file = \"Manhattan\"            }            else if (distance.measure == \"canberra\" | distance.measure ==                 \"dist.canberra\") {                message(\"Calculating Canberra distances...\")                distance.name.on.graph = \"Canberra distance\"                distance.name.on.file = \"Canberra\"            }            else if (distance.measure == \"euclidean\" | distance.measure ==                 \"dist.euclidean\") {                message(\"Calculating Euclidean distances...\")                distance.name.on.graph = \"Euclidean distance\"                distance.name.on.file = \"Euclidean\"            }            else if (distance.measure == \"cosine\" | distance.measure ==                 \"dist.cosine\") {                message(\"Calculating Cosine distances...\")                distance.name.on.graph = \"Cosine distance\"                distance.name.on.file = \"Cosine\"            }            else {                distance.name.on.graph = paste(\"Distance:\", distance.measure)                distance.name.on.file = distance.measure            }        }        message(\"MFW used: \")        for (i in seq(mfw.min, mfw.max, round(mfw.incr))) {            mfw = i            if (mfw > length(colnames(table.with.all.freqs))) {                mfw = length(colnames(table.with.all.freqs))            }            number.of.current.iteration = number.of.current.iteration +                 1            message(mfw, \" \", appendLF = FALSE)            if ((analysis.type == \"CA\") || (analysis.type ==                 \"BCT\") || (analysis.type == \"MDS\")) {                input.freq.table = table.with.all.freqs[, 1:mfw]                supported.measures = c(\"dist.euclidean\", \"dist.manhattan\",                   \"dist.canberra\", \"dist.delta\", \"dist.eder\",                   \"dist.argamon\", \"dist.simple\", \"dist.cosine\",                   \"dist.wurzburg\", \"dist.entropy\", \"dist.minmax\")                if (length(grep(distance.measure, supported.measures)) >                   1) {                  stop(\"Ambiguous distance method: which one did you want to use, really?\")                }                else if (length(grep(distance.measure, supported.measures)) ==                   0) {                  if (is.function(get(distance.measure)) == TRUE) {                    distance.table = do.call(distance.measure,                       list(x = input.freq.table))                    if (!inherits(distance.table, \"dist\")) {                      stop(\"it wasn't a real distance measure function applied, was it?\")                    }                  }                }                else {                  distance = supported.measures[grep(distance.measure,                     supported.measures)]                  if (distance %in% c(\"dist.manhattan\", \"dist.euclidean\",                     \"dist.canberra\")) {                    distance = gsub(\"dist.\", \"\", distance)                    distance.table = as.matrix(dist(input.freq.table,                       method = distance))                  }                  else if (distance %in% c(\"dist.simple\", \"dist.cosine\",                     \"dist.entropy\", \"dist.minmax\")) {                    distance.table = do.call(distance, list(x = input.freq.table[,                       1:mfw]))                  }                  else if (distance == \"dist.wurzburg\") {                    distance.table = do.call(distance, list(x = table.with.all.zscores[,                       1:mfw]))                  }                  else {                    distance.table = do.call(distance, list(x = table.with.all.zscores[,                       1:mfw], scale = FALSE))                  }                }                distance.table = as.matrix(distance.table)                rownames(distance.table) = gsub(\"(\\\\.txt$)||(\\\\.xml$)||(\\\\.html$)||(\\\\.htm$)\",                   \"\", rownames(table.with.all.freqs))                colnames(distance.table) = gsub(\"(\\\\.txt$)||(\\\\.xml$)||(\\\\.html$)||(\\\\.htm$)\",                   \"\", rownames(table.with.all.freqs))            }            groups = suppressMessages(process.metadata(metadata = metadata,                 filenames = rownames(table.with.all.freqs), filename.column = filename.column,                 grouping.column = grouping.column))            colors.of.pca.graph = assign.plot.colors(labels = groups,                 col = colors.on.graphs, opacity = 1)            name.of.the.method = \"\"            short.name.of.the.method = \"\"            mfw.info = mfw            plot.current.task = function() {                NULL            }            if (start.at == 1) {                start.at.info = \"\"            }            else {                start.at.info = paste(\"Started at\", start.at)            }            if (delete.pronouns == TRUE) {                pronouns.info = paste(\"Pronouns deleted\")            }            else {                pronouns.info = \"\"            }            if (culling.min == culling.max) {                culling.info = culling.min            }            else {                culling.info = paste(culling.min, \"-\", culling.max,                   sep = \"\")            }            if (analysis.type == \"CA\") {                name.of.the.method = \"Cluster Analysis\"                short.name.of.the.method = \"CA\"                if (dendrogram.layout.horizontal == TRUE) {                  dendrogram.margins = c(5, 4, 4, 8) + 0.1                }                else {                  dendrogram.margins = c(8, 5, 4, 4) + 0.1                }                plot.current.task = function() {                  par(mar = dendrogram.margins)                  if (linkage == \"nj\") {                    plot(nj(distance.table), font = 1, tip.color = colors.of.pca.graph)                  }                  else {                    clustered.data = hclust(as.dist(distance.table),                       method = linkage)                    colors.on.dendrogram = colors.of.pca.graph[clustered.data$order]                    tree.with.clusters = as.dendrogram(clustered.data,                       hang = 0)                    colLab = function(n) {                      if (is.leaf(n)) {                        a <- attributes(n)                        i <<- i + 1                        attr(n, \"nodePar\") <- c(a$nodePar, lab.col = mycols[i],                           pch = NA)                      }                      n                    }                    mycols = colors.on.dendrogram                    attributes(mycols) = NULL                    i = 0                    dendrogram.with.colors = dendrapply(tree.with.clusters,                       colLab)                    plot(dendrogram.with.colors, main = graph.main.title,                       horiz = dendrogram.layout.horizontal)                    if (dendrogram.layout.horizontal == TRUE) {                      title(sub = graph.subtitle)                    }                    else {                      title(sub = graph.subtitle, outer = TRUE,                         line = -1)                    }                  }                }            }            if (analysis.type == \"MDS\") {                name.of.the.method = \"Multidimensional Scaling\"                distance.name.on.graph = \"\"                distance.name.on.file = \"\"                short.name.of.the.method = \"MDS\"                mds.results = cmdscale(distance.table, eig = TRUE)                xy.coord = mds.results$points[, 1:2]                if (text.id.on.graphs == \"both\") {                  label.coord = cbind(mds.results$points[, 1],                     (mds.results$points[, 2] + (0.01 * label.offset *                       abs(max(mds.results$points[, 2]) - min(mds.results$points[,                         2])))))                }                else {                  label.coord = xy.coord                }                plot.area = define.plot.area(mds.results$points[,                   1], mds.results$points[, 2], xymargins = add.to.margins,                   v.offset = label.offset)                plot.current.task = function() {                  if (text.id.on.graphs == \"points\" || text.id.on.graphs ==                     \"both\") {                    plot(xy.coord, type = \"p\", ylab = \"\", xlab = \"\",                       xlim = plot.area[[1]], ylim = plot.area[[2]],                       main = graph.main.title, sub = graph.subtitle,                       col = colors.of.pca.graph, lwd = plot.line.thickness)                  }                  if (text.id.on.graphs == \"labels\") {                    plot(xy.coord, type = \"n\", ylab = \"\", xlab = \"\",                       xlim = plot.area[[1]], ylim = plot.area[[2]],                       main = graph.main.title, sub = graph.subtitle,                       col = colors.of.pca.graph, lwd = plot.line.thickness)                  }                  if (text.id.on.graphs == \"labels\" || text.id.on.graphs ==                     \"both\") {                    text(label.coord, rownames(label.coord),                       col = colors.of.pca.graph)                  }                  axis(1, lwd = plot.line.thickness)                  axis(2, lwd = plot.line.thickness)                  box(lwd = plot.line.thickness)                }            }            if (analysis.type == \"tSNE\") {                name.of.the.method = \"t-Distributed Stochastic Neighbor Embedding\"                short.name.of.the.method = \"t-SNE\"                distance.name.on.file = \"tSNE\"                distance.name.on.graph = \"t-SNE\"                plot.current.task = function() {                  ecb = function(x, y) {                    if (titles.on.graphs == TRUE) {                      graph.main.title = paste(graph.title, \"\\nt-SNE visualisation\")                    }                    else {                      graph.main.title = \"\"                    }                    plot(x, t = \"n\", main = graph.main.title,                       xlab = \"\", ylab = \"\", yaxt = \"n\", xaxt = \"n\")                    text(x, rownames(table.with.all.freqs[, 1:mfw]),                       cex = 0.3)                  }                  tsne(X = table.with.all.freqs[, 1:mfw], initial_dims = 50,                     epoch_callback = ecb, perplexity = 50, max_iter = 2000)                }            }            if (analysis.type == \"PCV\" || analysis.type == \"PCR\") {                name.of.the.method = \"Principal Components Analysis\"                short.name.of.the.method = \"PCA\"                distance.name.on.file = \"PCA\"                if (analysis.type == \"PCV\") {                  pca.results = prcomp(table.with.all.freqs[,                     1:mfw])                  distance.name.on.graph = \"Covariance matrix\"                }                else if (analysis.type == \"PCR\") {                  pca.results = prcomp(table.with.all.freqs[,                     1:mfw], scale = TRUE)                  distance.name.on.graph = \"Correlation matrix\"                }                expl.var = round(((pca.results$sdev^2)/sum(pca.results$sdev^2) *                   100), 1)                PC1_lab = paste(\"PC1 (\", expl.var[1], \"%)\", sep = \"\")                PC2_lab = paste(\"PC2 (\", expl.var[2], \"%)\", sep = \"\")                xy.coord = pca.results$x[, 1:2]                if (text.id.on.graphs == \"both\") {                  label.coord = cbind(pca.results$x[, 1], (pca.results$x[,                     2] + (0.01 * label.offset * abs(max(pca.results$x[,                     2]) - min(pca.results$x[, 2])))))                }                else {                  label.coord = xy.coord                }                plot.area = define.plot.area(pca.results$x[,                   1], pca.results$x[, 2], xymargins = add.to.margins,                   v.offset = label.offset)                plot.current.task = function() {                  if (pca.visual.flavour == \"classic\") {                    if (text.id.on.graphs == \"points\" || text.id.on.graphs ==                       \"both\") {                      plot(xy.coord, type = \"p\", xlim = plot.area[[1]],                         ylim = plot.area[[2]], xlab = \"\", ylab = PC2_lab,                         main = graph.main.title, sub = paste(PC1_lab,                           \"\\n\", graph.subtitle), col = colors.of.pca.graph,                         lwd = plot.line.thickness)                    }                    if (text.id.on.graphs == \"labels\") {                      plot(xy.coord, type = \"n\", xlim = plot.area[[1]],                         ylim = plot.area[[2]], xlab = \"\", ylab = PC2_lab,                         main = graph.main.title, sub = paste(PC1_lab,                           \"\\n\", graph.subtitle), col = colors.of.pca.graph,                         lwd = plot.line.thickness)                    }                    abline(h = 0, v = 0, col = \"gray60\", lty = 2)                    if (text.id.on.graphs == \"labels\" || text.id.on.graphs ==                       \"both\") {                      text(label.coord, rownames(pca.results$x),                         col = colors.of.pca.graph)                    }                    axis(1, lwd = plot.line.thickness)                    axis(2, lwd = plot.line.thickness)                    box(lwd = plot.line.thickness)                  }                  else if (pca.visual.flavour == \"loadings\") {                    biplot(pca.results, col = c(\"grey70\", \"black\"),                       cex = c(0.7, 1), xlab = \"\", ylab = PC2_lab,                       main = paste(graph.main.title, \"\\n\\n\",                         sep = \"\"), sub = paste(PC1_lab, \"\\n\",                         graph.subtitle, sep = \"\"), var.axes = FALSE)                  }                  else if (pca.visual.flavour == \"technical\") {                    layout(matrix(c(1, 2), 2, 2, byrow = TRUE),                       widths = c(3, 1))                    biplot(pca.results, col = c(\"black\", \"grey40\"),                       cex = c(1, 0.9), xlab = \"\", ylab = PC2_lab,                       main = paste(graph.main.title, \"\\n\\n\",                         sep = \"\"), sub = paste(PC1_lab, \"\\n\",                         graph.subtitle, sep = \"\"), var.axes = FALSE)                    abline(h = 0, v = 0, col = \"gray60\", lty = 3)                    row = mat.or.vec(nc = ncol(pca.results$x),                       nr = 1)                    for (i in 1:ncol(row)) {                      row[, i] = \"grey45\"                    }                    row[, 1] = \"black\"                    row[, 2] = \"black\"                    barplot(expl.var, col = row, xlab = \"Principal components\",                       ylab = \"Proportion of variance explained (in %)\")                    abline(h = 5, lty = 3)                  }                  else if (pca.visual.flavour == \"symbols\") {                    labels = c()                    for (c in rownames(pca.results$x)) {                      labels = c(labels, gsub(\"_.*\", \"\", c))                    }                    COOR = data.frame(pca.results$x[, 1:2], LABEL = labels,                       stringsAsFactors = TRUE)                    labels = c(levels(COOR$LABEL))                    sps = trellis.par.get(\"superpose.symbol\")                    sps$pch = 1:length(labels)                    trellis.par.set(\"superpose.symbol\", sps)                    ltheme = canonical.theme(color = FALSE)                    lattice.options(default.theme = ltheme)                    pl = xyplot(data = COOR, x = PC2 ~ PC1, xlab = paste(PC1_lab,                       \"\\n\", graph.subtitle, sep = \"\"), ylab = PC2_lab,                       groups = COOR$LABEL, sub = \"\", key = list(columns = 2,                         text = list(labels), points = Rows(sps,                           1:length(labels))), panel = function(x,                         ...) {                        panel.xyplot(x, ...)                        panel.abline(v = 0, lty = 3)                        panel.abline(h = 0, lty = 3)                      })                    plot(pl)                  }                }            }            if (analysis.type == \"BCT\") {                mfw.info = paste(mfw.min, \"-\", mfw.info, sep = \"\")                name.of.the.method = \"Bootstrap Consensus Tree\"                short.name.of.the.method = \"Consensus\"                if (linkage == \"nj\") {                  current.bootstrap.results = nj(as.dist(distance.table))                }                else {                  current.bootstrap.results = as.phylo(hclust(as.dist(distance.table),                     method = linkage))                }                bootstrap.list[[number.of.current.iteration]] = current.bootstrap.results            }            if (ngram.size > 1) {                ngram.value = paste(ngram.size, \"-grams\", sep = \"\")            }            else {                ngram.value = \"\"            }            if (titles.on.graphs == TRUE) {                graph.main.title = paste(graph.title, \"\\n\", name.of.the.method)                if (analysis.type == \"BCT\") {                  graph.subtitle = paste(mfw.info, \" MF\", toupper(analyzed.features),                     \" \", ngram.value, \" Culled @ \", culling.info,                     \"%\\n\", pronouns.info, \" \", distance.name.on.graph,                     \" Consensus \", consensus.strength, \" \", start.at.info,                     sep = \"\")                }                else {                  graph.subtitle = paste(mfw.info, \" MF\", toupper(analyzed.features),                     \" \", ngram.value, \" Culled @ \", culling.info,                     \"%\\n\", pronouns.info, \" \", distance.name.on.graph,                     \" \", start.at.info, sep = \"\")                }            }            else {                graph.main.title = \"\"                graph.subtitle = \"\"            }            if (is.character(custom.graph.filename) == TRUE &                 length(custom.graph.filename) > 0) {                graph.filename = custom.graph.filename            }            else {                if (analysis.type == \"BCT\") {                  graph.filename = paste(basename(getwd()), short.name.of.the.method,                     mfw.info, \"MFWs_Culled\", culling.info, pronouns.info,                     distance.name.on.file, \"C\", consensus.strength,                     start.at.info, sep = \"_\")                }                else {                  graph.filename = paste(basename(getwd()), short.name.of.the.method,                     mfw.info, \"MFWs_Culled\", culling.info, pronouns.info,                     distance.name.on.file, start.at.info, sep = \"_\")                }            }            if (analysis.type != \"BCT\") {                if (display.on.screen == TRUE) {                  plot.current.task()                }                if (write.pdf.file == TRUE) {                  pdf(file = paste(graph.filename, \"_%03d\", \".pdf\",                     sep = \"\"), width = plot.custom.width, height = plot.custom.height,                     pointsize = plot.font.size)                  plot.current.task()                  dev.off()                }                if (write.jpg.file == TRUE) {                  jpeg(filename = paste(graph.filename, \"_%03d\",                     \".jpg\", sep = \"\"), width = plot.custom.width,                     height = plot.custom.height, units = \"in\",                     res = 300, pointsize = plot.font.size)                  plot.current.task()                  dev.off()                }                if (write.svg.file == TRUE) {                  svg(filename = paste(graph.filename, \"_%03d\",                     \".svg\", sep = \"\"), width = plot.custom.width,                     height = plot.custom.height, pointsize = plot.font.size)                  plot.current.task()                  dev.off()                }                if (write.png.file == TRUE) {                  png(filename = paste(graph.filename, \"_%03d\",                     \".png\", sep = \"\"), width = plot.custom.width,                     height = plot.custom.height, units = \"in\",                     res = 300, pointsize = plot.font.size)                  plot.current.task()                  dev.off()                }            }            if (save.distance.tables == TRUE && exists(\"distance.table\") ==                 TRUE) {                distance.table.filename = paste(\"distance_table_\",                   mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\")                if (encoding == \"native.enc\") {                  data.to.be.saved = distance.table                }                else {                  data.to.be.saved = distance.table                  rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                     to = encoding)                  colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                     to = encoding)                }                write.table(file = distance.table.filename, data.to.be.saved)            }            features.actually.used = colnames(table.with.all.freqs[,                 1:mfw])            if (save.analyzed.features == TRUE) {                if (encoding == \"native.enc\") {                  data.to.be.saved = features.actually.used                }                else {                  data.to.be.saved = iconv(features.actually.used,                     to = encoding)                }                cat(data.to.be.saved, file = paste(\"features_analyzed_\",                   mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\"),                   sep = \"\\n\")            }            if (save.analyzed.freqs == TRUE) {                if (encoding == \"native.enc\") {                  data.to.be.saved = t(table.with.all.freqs[,                     1:mfw])                }                else {                  data.to.be.saved = t(table.with.all.freqs[,                     1:mfw])                  rownames(data.to.be.saved) = iconv(rownames(data.to.be.saved),                     to = encoding)                  colnames(data.to.be.saved) = iconv(colnames(data.to.be.saved),                     to = encoding)                }                write.table(data.to.be.saved, file = paste(\"frequencies_analyzed_\",                   mfw, \"mfw_\", current.culling, \"c.txt\", sep = \"\"))            }            if ((exists(\"distance.table\") == TRUE) & (network ==                 TRUE)) {                distances = distance.table                connections = matrix(data = 0, nrow = length(distances[,                   1]), ncol = length(distances[1, ]))                for (i in 1:length(distances[, 1])) {                  for (k in 1:linked.neighbors) {                    connections[i, (order(distances[i, ])[k +                       1])] = linked.neighbors - k + 1                  }                }                if (edge.weights == \"quadratic\") {                  connections = connections^2                }                else if (edge.weights == \"log\") {                  connections = log(connections + 1)                }                all.connections = all.connections + connections            }        }        message(\" \")    }    if ((exists(\"distance.table\") == TRUE) & (network == TRUE)) {        rownames(all.connections) = rownames(distances)        colnames(all.connections) = colnames(distances)        if (network.tables == \"edges\") {            edges = c()            for (i in 1:(length(all.connections[, 1]))) {                for (j in 1:(length(all.connections[1, ]))) {                  from = rownames(all.connections)[i]                  to = colnames(all.connections)[j]                  if (network.type == \"undirected\") {                    weight = all.connections[i, j] + all.connections[j,                       i]                    current.row = c(from, to, weight, \"undirected\")                  }                  else {                    weight = all.connections[i, j]                    current.row = c(from, to, weight, \"directed\")                  }                  if (weight > 0) {                    edges = rbind(edges, current.row)                  }                }            }            colnames(edges) = c(\"Source\", \"Target\", \"Weight\",                 \"Type\")            rownames(edges) = c(1:length(edges[, 1]))            edges = as.data.frame(edges)            edges.filename = paste(graph.filename, \"EDGES.csv\",                 sep = \"\")            write.csv(edges, file = edges.filename, quote = FALSE,                 row.names = FALSE)        }        else {            edges = c()            for (i in 1:(length(all.connections[, 1]))) {                for (j in 1:(length(all.connections[1, ]))) {                  from = c(1:length(rownames(all.connections)))[i]                  to = c(1:length(colnames(all.connections)))[j]                  if (network.type == \"undirected\") {                    weight = all.connections[i, j] + all.connections[j,                       i]                    current.row = c(from - 1, to - 1, weight,                       \"undirected\")                  }                  else {                    weight = all.connections[i, j]                    current.row = c(from - 1, to - 1, weight,                       \"directed\")                  }                  if (weight > 0) {                    edges = rbind(edges, current.row)                  }                }            }            colnames(edges) = c(\"Source\", \"Target\", \"Weight\",                 \"Type\")            rownames(edges) = c(1:length(edges[, 1]))            edges = as.data.frame(edges, stringsAsFactors = FALSE)            node.id = c(1:length(rownames(all.connections))) -                 1            node.names = rownames(all.connections)            node.classes = gsub(\"_.*\", \"\", node.names)            node.classes.numeric = as.numeric(factor(gsub(\"_.*\",                 \"\", node.names)))            nodes = cbind(node.id, node.names, node.classes,                 node.classes.numeric)            colnames(nodes) = c(\"Id\", \"Label\", \"Classes\", \"Group\")            nodes = as.data.frame(nodes, stringsAsFactors = FALSE)            edges.filename = paste(graph.filename, \"EDGES.csv\",                 sep = \"\")            write.csv(edges, file = edges.filename, quote = FALSE,                 row.names = FALSE)            nodes.filename = paste(graph.filename, \"NODES.csv\",                 sep = \"\")            write.csv(nodes, file = nodes.filename, quote = FALSE,                 row.names = FALSE)        }    }    if (length(all.connections) == 1) {        rm(all.connections)    }    if (analysis.type == \"BCT\") {        if (length(bootstrap.list) <= 2) {            message(\"\\n\\nSORRY, BUT YOU ARE EXPECTING TOO MUCH...!\\n\",                 \"There should be at least 3 iterations to make a consensus tree\\n\")        }        else {            plot.current.task = function() {                plot(consensus(bootstrap.list, p = consensus.strength),                   type = \"u\", font = 1, lab4ut = \"axial\", tip.color = colors.of.pca.graph)                title(main = graph.main.title)                title(sub = graph.subtitle)            }            if (display.on.screen == TRUE) {                plot.current.task()            }            if (write.pdf.file == TRUE) {                pdf(file = paste(graph.filename, \"_%03d\", \".pdf\",                   sep = \"\"), width = plot.custom.width, height = plot.custom.height,                   pointsize = plot.font.size)                plot.current.task()                dev.off()            }            if (write.jpg.file == TRUE) {                jpeg(filename = paste(graph.filename, \"_%03d\",                   \".jpg\", sep = \"\"), width = plot.custom.width,                   height = plot.custom.height, units = \"in\",                   res = 300, pointsize = plot.font.size)                plot.current.task()                dev.off()            }            if (write.svg.file == TRUE) {                svg(filename = paste(graph.filename, \"_%03d\",                   \".svg\", sep = \"\"), width = plot.custom.width,                   height = plot.custom.height, pointsize = plot.font.size)                plot.current.task()                dev.off()            }            if (write.png.file == TRUE) {                png(filename = paste(graph.filename, \"_%03d\",                   \".png\", sep = \"\"), width = plot.custom.width,                   height = plot.custom.height, units = \"in\",                   res = 300, pointsize = plot.font.size)                plot.current.task()                dev.off()            }        }    }    features = mfw.list.of.all    if (exists(\"pca.results\") == TRUE) {        pca.coordinates = pca.results$x        pca.rotation = pca.results$rotation        pca.sdev = pca.results$sdev        pca.var.exp = round((pca.results$sdev^2)/sum(pca.results$sdev^2) *             100, 2)    }    if (exists(\"all.connections\") == TRUE) {        table.edges = all.connections    }    if (exists(\"edges\") == TRUE & length(edges) > 1) {        list.of.edges = edges    }    if (exists(\"nodes\") == TRUE) {        list.of.nodes = nodes    }    if (exists(\"distance.table\")) {        attr(distance.table, \"description\") = \"final distances between each pair of samples\"        class(distance.table) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"frequencies.0.culling\")) {        attr(frequencies.0.culling, \"description\") = \"frequencies of words/features accross the corpus\"        class(frequencies.0.culling) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"table.with.all.freqs\")) {        attr(table.with.all.freqs, \"description\") = \"frequencies of words/features accross the corpus\"        class(table.with.all.freqs) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"table.with.all.zscores\")) {        attr(table.with.all.zscores, \"description\") = \"z-scored frequencies accross the corpus\"        class(table.with.all.zscores) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"features\")) {        attr(features, \"description\") = \"features (e.g. words, n-grams, ...) applied to data\"        class(features) = \"stylo.data\"    }    if (exists(\"features.actually.used\")) {        attr(features.actually.used, \"description\") = \"features (e.g. frequent words) actually analyzed\"        class(features.actually.used) = \"stylo.data\"    }    if (exists(\"table.of.edges\")) {        attr(table.of.edges, \"description\") = \"edges of a network of stylometric similarities\"    }    if (exists(\"list.of.edges\")) {        attr(list.of.edges, \"description\") = \"edges of a network of stylometric similarities\"    }    if (exists(\"list.of.nodes\")) {        attr(list.of.nodes, \"description\") = \"nodes of a network of stylometric similarities\"    }    if (exists(\"pca.coordinates\")) {        attr(pca.coordinates, \"description\") = \"PCA matrix of coordinates for particular PCs\"        class(pca.coordinates) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"pca.rotation\")) {        attr(pca.rotation, \"description\") = \"PCA matrix of variable loadings' eigenvectors\"        class(pca.rotation) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"pca.sdev\")) {        attr(pca.sdev, \"description\") = \"PCA: standard deviations or particular PCs\"        class(pca.sdev) = c(\"stylo.data\", \"matrix\")    }    if (exists(\"pca.var.exp\")) {        attr(pca.var.exp, \"description\") = \"PCA: explained variance [%] for particular PCs\"        class(pca.var.exp) = c(\"stylo.data\", \"matrix\")    }    results.stylo = list()    variables.to.save = c(\"distance.table\", \"frequencies.0.culling\",         \"table.with.all.freqs\", \"table.with.all.zscores\", \"features\",         \"features.actually.used\", \"pca.coordinates\", \"pca.rotation\",         \"pca.sdev\", \"pca.var.exp\", \"table.of.edges\", \"list.of.edges\",         \"list.of.nodes\")    filtered.variables = ls()[ls() %in% variables.to.save]    for (i in filtered.variables) {        results.stylo[[i]] = get(i)    }    results.stylo$call = match.call()    results.stylo$name = call(\"stylo\")    class(results.stylo) = \"stylo.results\"    setwd(original.path)    return(results.stylo)})(gui = FALSE)\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Depending on your chosen options, some results should have been written\n",
      "\n",
      "R[write to console]: into a few files; you should be able to find them in your current\n",
      "\n",
      "R[write to console]: (working) directory. Usually, these include a list of words/features\n",
      "\n",
      "R[write to console]: used to build a table of frequencies, the table itself, a file containing\n",
      "\n",
      "R[write to console]: recent configuration, etc.\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Advanced users: you can pipe the results to a variable, e.g.:\n",
      "\n",
      "R[write to console]: \t important.contribution = stylo()\n",
      "\n",
      "R[write to console]: this will create a class \"important.contribution\" containing some presumably\n",
      "\n",
      "R[write to console]: interesting stuff. The class created, you can type, e.g.:\n",
      "\n",
      "R[write to console]: \t summary(important.contribution)\n",
      "\n",
      "R[write to console]: to see which variables are stored there and how to use them.\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: for suggestions how to cite this software, type: citation(\"stylo\")\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: using current directory...\n",
      "\n",
      "R[write to console]:  \n",
      "\n",
      "R[write to console]: GUI could not be launched -- default settings will be used;\n",
      "\n",
      "R[write to console]: otherwise please pass your variables as command-line agruments\n",
      "\n",
      "\n",
      "R[write to console]: Performing no sampling (using entire text as sample)\n",
      "\n",
      "\n",
      "R[write to console]: slicing input text into tokens...\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "turning words into features, e.g. char n-grams (if applicable)...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Total nr. of samples in the corpus: 34\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: The corpus consists of 3 tokens\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: processing  34  text samples\n",
      "\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: .\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: combining frequencies into a table...\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "\n",
      "R[write to console]: culling @ 0\tavailable features (words) 3\n",
      "\n",
      "R[write to console]: Calculating z-scores... \n",
      "\n",
      "\n",
      "R[write to console]: Calculating classic Delta distances...\n",
      "\n",
      "R[write to console]: MFW used: \n",
      "\n",
      "R[write to console]: 3 \n",
      "R[write to console]:  \n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Function call:\n",
      "\n",
      "R[write to console]: stylo()\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Depending on your chosen options, some results should have been written\n",
      "\n",
      "R[write to console]: into a few files; you should be able to find them in your current\n",
      "\n",
      "R[write to console]: (working) directory. Usually, these include a list of words/features\n",
      "\n",
      "R[write to console]: used to build a table of frequencies, the table itself, a file containing\n",
      "\n",
      "R[write to console]: recent configuration, etc.\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Advanced users: you can pipe the results to a variable, e.g.:\n",
      "\n",
      "R[write to console]: \t my.discovery = stylo()\n",
      "\n",
      "R[write to console]: this will create a class \"my.discovery\" containing some presumably\n",
      "\n",
      "R[write to console]: interesting stuff. The class created, you can type, e.g.:\n",
      "\n",
      "R[write to console]: \t summary(my.discovery)\n",
      "\n",
      "R[write to console]: to see which variables are stored there and how to use them.\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: for suggestions how to cite this software, type: citation(\"stylo\")\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 9 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            distance.table\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "        <span>FloatMatrix with 1156 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            features\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "        <span>StrVector with 3 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'k'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'm'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            't'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            features.actually.used\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "        <span>StrVector with 3 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'k'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'm'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            't'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            ...\n",
       "            </th>\n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            table.with.all.zscores\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "        <span>FloatMatrix with 102 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            -0.171499\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            call\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            name\n",
       "            </th>\n",
       "            <td>\n",
       "            \n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x1076e8110> [19]\n",
       "R classes: ('stylo.results',)\n",
       "[FloatSexp..., StrSexpVe..., StrSexpVe..., FloatSexp..., ..., FloatSexp..., FloatSexp..., LangSexpV..., LangSexpV...]\n",
       "  distance.table: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x10ebcf650> [14]\n",
       "  features: <class 'rpy2.rinterface_lib.sexp.StrSexpVector'>\n",
       "  <rpy2.rinterface_lib.sexp.StrSexpVector object at 0x11aa20fd0> [16]\n",
       "  features.actually.used: <class 'rpy2.rinterface_lib.sexp.StrSexpVector'>\n",
       "  <rpy2.rinterface_lib.sexp.StrSexpVector object at 0x11aa23a10> [16]\n",
       "  frequencies.0.culling: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x11aa22610> [14]\n",
       "  list.of.edges: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x11aa23a10> [19]\n",
       "  table.with.all.freqs: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x11aa22750> [14]\n",
       "  table.with.all.zscores: <class 'rpy2.rinterface.FloatSexpVector'>\n",
       "  <rpy2.rinterface.FloatSexpVector object at 0x11aa223d0> [14]\n",
       "  call: <class 'rpy2.rinterface.LangSexpVector'>\n",
       "  <rpy2.rinterface.LangSexpVector object at 0x11aa20cd0> [6]\n",
       "  name: <class 'rpy2.rinterface.LangSexpVector'>\n",
       "  <rpy2.rinterface.LangSexpVector object at 0x11aa22610> [6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "R.setwd(\".\")\n",
    "R.stylo(gui=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
